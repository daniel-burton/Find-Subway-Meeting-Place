{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, math, os\n",
    "from datetime import datetime\n",
    "\n",
    "os.chdir('/home/dan/code/gtfs_graph_builder/') # change this for your own file system\n",
    "\n",
    "WAIT_TIME = 600 #***\n",
    "\n",
    "######################################\n",
    "# This file processes an NYC MTA GTFS dataset and creates a graph representing \n",
    "# each station stop as a node, with edges representing averaged travel time.\n",
    "# Lots of complexities of the system are ironed out and special schedules are\n",
    "# ignored. All trains are portrayed as weekday non-rush-hour service.\n",
    "# Data is built up using station and trip information to parse stop times.\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_ids represents some odd Q train behavior I could not figure out other than\n",
    "# hardcoding the 'bad' trip labels in.\n",
    "bad_ids = [ 'BFA18GEN-N091-Weekday-00_049850_N..N65R', 'BFA18GEN-N091-Weekday-00_100200_N..N65R',\n",
    "            'BFA18GEN-N091-Weekday-00_045550_N..N65R', 'BFA18GEN-N091-Weekday-00_089800_N..N65R',\n",
    "            'BFA18GEN-N091-Weekday-00_093300_N..N69R', 'BFA18GEN-N091-Weekday-00_094500_N..N65R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading trips...\n"
     ]
    }
   ],
   "source": [
    "# get trips from trips.txt-- includes unique id, route, service, and \"sign\"\n",
    "# each \"trip\" is one end-to-end subway journey scheduled for a particular time\n",
    "# think \"the 8AM Manhattan-Bound 4 Train\"\n",
    "\n",
    "all_trips = {}\n",
    "\n",
    "print('Reading trips...')\n",
    "with open(\"./data/trips.txt\", 'r') as trips_txt:\n",
    "    next(trips_txt)\n",
    "    for line in trips_txt:\n",
    "        line = line.split(\",\")\n",
    "        route = line[0]\n",
    "        service = line[1]\n",
    "        trip = line[2]\n",
    "        sign = line[3]\n",
    "        if trip not in all_trips:\n",
    "            all_trips[trip] = {\"route\": route, \"service\": service, 'sign': sign}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions: \n",
    "def is_daytime(a_time):\n",
    "    \"\"\"ensures a time is between 10AM and 3PM\"\"\"\n",
    "    NIGHTTIME = datetime.strptime(\"15:00:00\", \"%H:%M:%S\")\n",
    "    MORNING = datetime.strptime(\"10:00:00\", \"%H:%M:%S\")\n",
    "\n",
    "    if a_time < MORNING or a_time > NIGHTTIME:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def get_name(station_number):\n",
    "    \"\"\"returns the name of a station, given the MTA station identifier\"\"\"\n",
    "    return stations[station_number[:3]]['name']\n",
    "\n",
    "def get_line(name):\n",
    "    \"\"\"return the Line ('A', '2', etc) of a train given station identifier\"\"\"\n",
    "    return name.split('#')[1]\n",
    "\n",
    "def get_line_name(station):\n",
    "    \"\"\"clean up line names, turn abbreviations into proper name\"\"\"\n",
    "    station = get_line(station)\n",
    "    if station =='GS':\n",
    "        return 'GS_Shuttle'\n",
    "    elif station == 'FS':\n",
    "        return 'FA_Shuttle'\n",
    "    elif station == 'AR' or station == 'AL':\n",
    "        # \"A\" train forks to Lefferts (AL) and Far Rockaway (AR)\n",
    "        return 'A'\n",
    "    elif station == 'H':\n",
    "        return 'R_Shuttle'\n",
    "    else:\n",
    "        return station\n",
    "\n",
    "def fix_time(raw):\n",
    "    # GTFS allows times greater than 24-- because a train that starts on a given day must be included in that day's schedule\n",
    "    if int(raw[:2]) >= 24:\n",
    "        return str('0' + str(int(raw[:2]) - 24) + raw[2:])\n",
    "    else:\n",
    "        return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing stops...\n"
     ]
    }
   ],
   "source": [
    "#import stops from stops.txt\n",
    "\n",
    "stations = {}\n",
    "reverse_stations = {}\n",
    "\n",
    "print('Importing stops...')\n",
    "with open(\"./data/stops.txt\", \"r\") as stops_file:\n",
    "    next(stops_file)\n",
    "    for line in stops_file:\n",
    "        line = line.split(\",\")\n",
    "        \n",
    "        stations[line[0]] = {\"name\": line[2], \"parent\": line[9].strip(), 'lat': float(line[4]), 'lon': float(line[5])}\n",
    "        reverse_stations[line[2]] = line[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Stop Times...\n"
     ]
    }
   ],
   "source": [
    "stops = []\n",
    "\n",
    "#columns:\n",
    "#0 trip_id, #1 arrival_time, # 2 departure_time, #3 stop_id, #4 stop_sequence,\n",
    "#5 stop_headsign, #6 pickup_type, #7 drop_off_type, #8 shape_dist_traveled \n",
    "\n",
    "print('Importing Stop Times...')\n",
    "with open(\"./data/stop_times.txt\", 'r') as stop_times:\n",
    "    next(stop_times)\n",
    "    for line in stop_times:\n",
    "        line = line.split(\",\")\n",
    "        trip_id = line[0] #trip ID\n",
    "        arrival = line[1] #time it arrived at station\n",
    "        departure = line[2] #time it leaves station\n",
    "        destined = all_trips[trip_id]['sign']\n",
    "        #its displayed final destination, 'sign' column is blank in stop_times\n",
    "        stop = line[3] # current stop\n",
    "        sequence = line[4] #what number stop this is in the route\n",
    "        route = all_trips[trip_id]['route'] #what route (A, C, 1, 2, 3, etc)\n",
    "\n",
    "        arrival = datetime.strptime(fix_time(arrival),\"%H:%M:%S\")\n",
    "        departure = datetime.strptime(fix_time(departure), \"%H:%M:%S\")\n",
    "\n",
    "        if sequence == \"1\": #if it's the first stop on a path it won't have a travel time\n",
    "            started = stop\n",
    "            previous = ''\n",
    "            prev_departure_time = ''\n",
    "            edge_time = None\n",
    "        else:\n",
    "            wait_time = (departure - arrival).seconds\n",
    "            edge_time = (arrival - prev_departure_time).seconds + wait_time\n",
    "            #edge_time is time between arrival at this station and arrival at next station\n",
    "\n",
    "        if route == 'A':\n",
    "        #separate Lefferts and Rockway bound A trains, the only train that branches all day\n",
    "            if destined == 'Ozone Park - Lefferts Blvd' or started == 'Ozone Park - Lefferts Blvd':\n",
    "                route = 'AL' #A-Lefferts\n",
    "            else:\n",
    "                route = 'AR' #A-Rockaway\n",
    "\n",
    "        if trip_id not in bad_ids:\n",
    "            #bad_ids is a list of Q trains that run on the N line in the very early AM\n",
    "            stops.append({'route': route, \"id\": trip_id, 'travel_time': edge_time,\n",
    "                          'sequence': sequence, 'previous': previous,\n",
    "                          \"arrival\": arrival, \"departure\": departure,\n",
    "                          \"stop\": stop, 'started':started, 'destined':destined})\n",
    "        previous = stop\n",
    "        prev_departure_time = departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect all weekday service patterns\n",
    "\n",
    "weekday_services = set()\n",
    "\n",
    "for trip in all_trips:\n",
    "    service = all_trips[trip]['service']\n",
    "    name = all_trips[trip]['route']\n",
    "    if 'Weekday' in service and 'SIR' not in service:\n",
    "        #sorry Staten Island...\n",
    "        weekday_services.add(service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoints (and also, startpoints) for trains running a full route \n",
    "#(not stopping short or taking a rush-hour branch)\n",
    "\n",
    "full_route_ends = {'1': ['South Ferry', 'Van Cortlandt Park - 242 St'],\n",
    "                   '2': ['Wakefield - 241 St', 'Flatbush Av - Brooklyn College'],\n",
    "                   '3': ['New Lots Av', 'Harlem - 148 St'],\n",
    "                   '4': ['Crown Hts - Utica Av', 'Woodlawn'],\n",
    "                   '5': ['Eastchester - Dyre Av', 'Flatbush Av - Brooklyn College'],\n",
    "                   '6': ['Pelham Bay Park', 'Brooklyn Bridge - City Hall'],\n",
    "                   '7': ['34 St - 11 Av', 'Flushing - Main St'],\n",
    "                   'GS': ['Grand Central - 42 St', 'Times Sq - 42 St'],\n",
    "                   'A': ['Inwood - 207 St', 'Ozone Park - Lefferts Blvd',\n",
    "                         'Far Rockaway - Mott Av', 'Rockaway Park - Beach 116 St'],\n",
    "                   'AL': ['Inwood - 207 St', 'Ozone Park - Lefferts Blvd'],\n",
    "                   'AR': ['Far Rockaway - Mott Av', 'Inwood - 207 St'],\n",
    "                   'B': ['Brighton Beach', '145 St'],\n",
    "                   'C': ['Euclid Av', '168 St'],\n",
    "                   'D': ['Coney Island - Stillwell Av', 'Norwood - 205 St'],\n",
    "                   'E': ['World Trade Center', 'Jamaica Center - Parsons/Archer'],\n",
    "                   'F': ['Coney Island - Stillwell Av', 'Jamaica - 179 St'],\n",
    "                   'FS': ['Prospect Park', 'Franklin Av'],\n",
    "                   'G': ['Church Av', 'Court Sq'],\n",
    "                   'H': ['Broad Channel', 'Rockaway Park - Beach 116 St'],\n",
    "                   'J': ['Broad St', 'Jamaica Center - Parsons/Archer'],\n",
    "                   'Z': [], #ignore the Z... only runs at rush hour\n",
    "                   'L': ['8 Av', 'Canarsie - Rockaway Pkwy'],\n",
    "                   'M': ['Middle Village - Metropolitan Av', 'Forest Hills - 71 Av'],\n",
    "                   'N': ['Coney Island - Stillwell Av', 'Astoria - Ditmars Blvd'],\n",
    "                   'W': ['Whitehall St', 'Astoria - Ditmars Blvd'],\n",
    "                   'Q': ['96 St', 'Coney Island - Stillwell Av'],\n",
    "                   'R': ['Bay Ridge - 95 St', 'Forest Hills - 71 Av']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to find \"good\" trains \n",
    "#(started and ended at right stations, daytime, weekday, doesn't change routes, not \"x\" type express)\n",
    "\n",
    "def normal_route(route):\n",
    "    '''remove \"X\" rush hour express routes and Staten Island trains'''\n",
    "    if route[-1] != 'X' and 'SI' not in route:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def daytime_weekday_service(service, arrival):\n",
    "    '''stop is made on a weekday during the day'''\n",
    "    if is_daytime(arrival) and service in weekday_services:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def not_first(prev_stop):\n",
    "    '''not first stop'''\n",
    "    return prev_stop != ''\n",
    "\n",
    "def normal_path(started, destination):\n",
    "    ''' not first stop, destination and start point are correct for this route'''\n",
    "    return destination in full_route_ends[route] and get_name(started) in full_route_ends[route]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Stop Times...\n",
      "\tDone.\n"
     ]
    }
   ],
   "source": [
    "edges_pre_avg = {}\n",
    "previous_route = ''\n",
    "\n",
    "print(\"Parsing Stop Times...\")\n",
    "for stop in stops:\n",
    "    '''parse the stops read in from stop_times earlier and create the edges'''\n",
    "    trip_id = stop[\"id\"]\n",
    "    parent = stop['stop']\n",
    "    sequence = stop['sequence']\n",
    "    destined = stop['destined']\n",
    "    started = stop['started']\n",
    "    now = stop['stop'] + '#' + route\n",
    "    service = all_trips[stop['id']]['service']\n",
    "    route = stop['route']\n",
    "    name = stations[stop['stop']]['name']\n",
    "    previous_stop = stop['previous'] + \"#\" + route\n",
    "    arrival = stop['arrival']\n",
    "    time = stop['travel_time']\n",
    "\n",
    "    if not_first(previous_stop) and normal_route(route) and normal_path(started, destined) and daytime_weekday_service(service, arrival):\n",
    "        # I separated all these functions to avoid 1 function with 6 positional args...\n",
    "        # still ugly\n",
    "\n",
    "        if len(previous_stop) > 3:\n",
    "            # somehow some '' previous stops were sneaking past the check above\n",
    "            if previous_stop not in edges_pre_avg:\n",
    "                edges_pre_avg[previous_stop] = {}\n",
    "            if now not in edges_pre_avg[previous_stop]:\n",
    "                edges_pre_avg[previous_stop][now] = []\n",
    "            edges_pre_avg[previous_stop][now].append(time)\n",
    "            if now not in edges_pre_avg:\n",
    "                edges_pre_avg[now] = {}\n",
    "    previous_route = route\n",
    "print('\\tDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering edges...\n"
     ]
    }
   ],
   "source": [
    "# This was an issue because of the way I parsed stops-- endpoints were missing\n",
    "# for instance, the last Outward-Bound stop on the 4 is Utica,\n",
    "# which got put into the data as an edge-endpoint but not a potential start.\n",
    "# Even though it could be a startpoint for a transfer edge.\n",
    "\n",
    "empty_ends = [] #endpoints with zero connections as of yet-- add back in when adding transfers\n",
    "filtered_pre_avg = {}\n",
    "\n",
    "print('Filtering edges...')\n",
    "for start in edges_pre_avg:\n",
    "    if len(edges_pre_avg[start]) == 0:\n",
    "        empty_ends.append(start)\n",
    "    else:\n",
    "        filtered_pre_avg[start] = edges_pre_avg[start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaging edges...\n"
     ]
    }
   ],
   "source": [
    "#filter for most common path (to delete uncommon branches or trains that unexpectedly go local)\n",
    "#then average the times.\n",
    "#note that removing branches is OK because the two A train destinations are treated as separate lines\n",
    "#all other branching routes are only during rush hour-- they're ignored for this version of the graph\n",
    "\n",
    "averaged_edges = {}\n",
    "\n",
    "print('Averaging edges...')\n",
    "for start, ends in filtered_pre_avg.items():\n",
    "    if start not in averaged_edges:\n",
    "        averaged_edges[start] = {}\n",
    "    maximum = 0\n",
    "    maximum_key = ''\n",
    "    for end, times in ends.items():\n",
    "        if len(times) > maximum:\n",
    "            maximum = len(times)\n",
    "            maximum_key = end\n",
    "    values = edges_pre_avg[start][maximum_key]\n",
    "    tup = ('r' , math.ceil(sum(values) / len(values))) # *\n",
    "    averaged_edges[start][maximum_key] = tup # *\n",
    "\n",
    "# get sub-stops for every parent stop-- a sub stop represents one train that stops there \n",
    "# EG Nostrand Avenue 3 train stop has 2 sub_stops: 3 train Outbound and Inbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding sub-stops for each stop...\n"
     ]
    }
   ],
   "source": [
    "sub_stops = {}\n",
    "\n",
    "print('Finding sub-stops for each stop...')\n",
    "for start, ends in averaged_edges.items():\n",
    "    parent = start[:3]\n",
    "\n",
    "    if parent not in sub_stops:\n",
    "        sub_stops[parent] = []\n",
    "    if start not in sub_stops[parent]:\n",
    "        sub_stops[parent].append(start)\n",
    "\n",
    "    for end in ends:\n",
    "        end_parent = end[:3]\n",
    "\n",
    "        if end_parent not in sub_stops:\n",
    "            sub_stops[end_parent] = []\n",
    "        if end not in sub_stops[end_parent]:\n",
    "            sub_stops[end_parent].append(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensuring all edges are mirrored-- you can get here from there.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('r', 240)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MTA treats some stops as multiple parent stops-- like the 2-3-4-5 vs D-N-R #** check this cell carefully\n",
    "# platforms at Atlantic. sub_stops only includes sub_stops of one parent\n",
    "\n",
    "\n",
    "# check every combination of start and end, and make sure the reverse\n",
    "# trip is also in averaged_edges. If you can get there from here, you can also\n",
    "# get here from there.\n",
    "\n",
    "#averaged_edges_fixed = dict(averaged_edges)\n",
    "averaged_edges_fixed = {}\n",
    "\n",
    "def reverse_stop(stop):\n",
    "    #returns the opposite direction train\n",
    "    return stop[:3] + 'S' + stop[4:] if stop[3] == 'N' else stop[:3] + 'N' + stop[4:]\n",
    "\n",
    "print('Ensuring all edges are mirrored-- you can get here from there.')\n",
    "for start, ends in averaged_edges.items():\n",
    "    reverse_start = reverse_stop(start)\n",
    "    averaged_edges_fixed[start] = {}\n",
    "    if start not in ['H01N#AR', 'H01S#AR']: #H01N is the Aqueduct Racetrack-- only Northbound trains stop there\n",
    "        for end, time_tup in ends.items():\n",
    "            averaged_edges_fixed[start][end] = time_tup\n",
    "            reverse_end = reverse_stop(end)\n",
    "            if get_line(reverse_start) == get_line(reverse_end):\n",
    "                if reverse_end not in averaged_edges_fixed and reverse_end not in ['H01N#AR', 'H01S#AR']:#\n",
    "                    #print(get_line(reverse_end), \"From: \",reverse_end, get_name(reverse_end))\n",
    "                    averaged_edges_fixed[reverse_end] = {}\n",
    "                if reverse_end not in ['H01N#AR', 'H01S#AR', 'H02N#AR', 'H02S#AR'] and reverse_start not in averaged_edges_fixed[reverse_end]:\n",
    "                    #print('\\t to:', reverse_start, get_name(reverse_start))\n",
    "                    averaged_edges_fixed[reverse_end][reverse_start] = time_tup\n",
    "\n",
    "#for some reason this station is not getting added-- add it here\n",
    "averaged_edges_fixed['A65S#AL'] = {'A65N#AL': ('t', 820)} #***\n",
    "#create graph_without_transfers: a dictionary of ONLY the next stop from a given stop. no transfers.\n",
    "\n",
    "averaged_edges_fixed['M11S#J'].pop('M16S#J') #somehow an express train was sneaking through the filter above... #**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H01N#AR']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create next_stop_by_stop: for every stop, the next stop only. #* whole cell #** whole cell\n",
    "next_stop_by_stop = {}\n",
    "\n",
    "for start, ends in averaged_edges_fixed.items():\n",
    "    for end in ends:\n",
    "        #print('\\t', end)\n",
    "        #end = get_name(end)\n",
    "        if start not in next_stop_by_stop:\n",
    "            next_stop_by_stop[start] = []\n",
    "        if end not in next_stop_by_stop[start]:\n",
    "            next_stop_by_stop[start].append(end)\n",
    "#print(next_stop_by_stop)\n",
    "        \n",
    "next_stop_by_stop['H02N#AR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in transfers...\n"
     ]
    }
   ],
   "source": [
    "# for line in transfers get the data and create transfer_edges\n",
    "\n",
    "transfers_from_file = {}\n",
    "\n",
    "print('Reading in transfers...')\n",
    "with open('./data/transfers.txt', 'r') as transfer_file:\n",
    "    next(transfer_file)\n",
    "    for line in transfer_file:\n",
    "        from_station, to, _, time = line.split(\",\")\n",
    "        if from_station != '140':\n",
    "            if from_station not in transfers_from_file:\n",
    "                transfers_from_file[from_station] = {}\n",
    "            if to not in transfers_from_file[from_station] and '140' not in to:\n",
    "                transfers_from_file[from_station][to] = int(time) + WAIT_TIME #**\n",
    "#print(transfers_from_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding self-transfers from transfer file...\n",
      "Ensuring all end-of-line stops exist for transfers...\n"
     ]
    }
   ],
   "source": [
    "# some transfer edges don't exist for self-transfer... find those and add with a 500 second wait\n",
    "transfers_with_self_transfers = dict(transfers_from_file)\n",
    "\n",
    "\n",
    "print('Adding self-transfers from transfer file...')\n",
    "for stop in sub_stops:\n",
    "    if stop not in transfers_with_self_transfers:\n",
    "        transfers_with_self_transfers[stop] = {stop: WAIT_TIME} #**\n",
    "    else:\n",
    "        if stop not in transfers_with_self_transfers[stop]:\n",
    "            transfers_with_self_transfers[stop][stop] = WAIT_TIME #**\n",
    "\n",
    "print('Ensuring all end-of-line stops exist for transfers...')\n",
    "for stop in empty_ends:\n",
    "    parent = stop[:3]\n",
    "    if stop not in transfers_with_self_transfers:\n",
    "        transfers_with_self_transfers[parent] = {parent: WAIT_TIME} #**\n",
    "    else:\n",
    "        if stop not in transfers_with_self_transfers[stop]:\n",
    "            transfers_with_self_transfers[parent][parent] = WAIT_TIME #**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding self-transfers that were missing from file...\n"
     ]
    }
   ],
   "source": [
    "# add self-transfers to all edges\n",
    "\n",
    "edges_with_self_transfers= dict(averaged_edges_fixed)\n",
    "\n",
    "print('Adding self-transfers that were missing from file...')\n",
    "for start, ends in averaged_edges.items():\n",
    "    parent = start[:3]\n",
    "    for sub_stop in sub_stops[parent]:\n",
    "        neighbor = sub_stop[:3]\n",
    "        time_tup = ('t', transfers_with_self_transfers[parent][neighbor]) #*\n",
    "        if sub_stop != start:\n",
    "            edges_with_self_transfers[start][sub_stop] = time_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup second-check on missing self-transfers...\n"
     ]
    }
   ],
   "source": [
    "# make sure transfer edges that are transfer -only- (IE, they exist in Edges as ends but not starts) are added\n",
    "\n",
    "edges_with_self_transfers_complete = dict(edges_with_self_transfers)\n",
    "\n",
    "print('Cleanup second-check on missing self-transfers...')\n",
    "for start, ends in edges_with_self_transfers.items():\n",
    "    for end in ends:\n",
    "        parent = end[:3]\n",
    "        if end not in edges_with_self_transfers:\n",
    "            edges_with_self_transfers_complete[end] = {}\n",
    "            for sub in sub_stops[parent]:\n",
    "                if sub != end: #* line below\n",
    "                    edges_with_self_transfers_complete[end][sub] = ('t', transfers_with_self_transfers[parent][parent])\n",
    "    \n",
    "edges_with_self_transfers['A65S#AL'] = {'A65N#AL': ('t', 820)} #***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining trip edges with transfer edges...\n"
     ]
    }
   ],
   "source": [
    "# note: transfers_with_self_transfers can have multiple transfers for 1 origin\n",
    "\n",
    "edges_with_all_transfers = dict(edges_with_self_transfers_complete)\n",
    "\n",
    "print('Combining trip edges with transfer edges...')\n",
    "for start, ends in edges_with_self_transfers.items():\n",
    "    parent = start[:3]\n",
    "    if parent in transfers_with_self_transfers:\n",
    "        for end, time in transfers_with_self_transfers[parent].items():\n",
    "            for sub in sub_stops[end]:\n",
    "                 if sub not in edges_with_all_transfers[start]:\n",
    "                    if time < WAIT_TIME:\n",
    "                        time_tup = ('t', time + WAIT_TIME) #*\n",
    "                    else: #**\n",
    "                        time_tup = ('t', time) #**\n",
    "                    edges_with_all_transfers[start][sub] = time_tup #* #** why is time a number and not a tuple?\n",
    "#print(edges_with_all_transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing erroneous transfers...\n"
     ]
    }
   ],
   "source": [
    "# filter out self-transfers like 'get off this 4 train, wait 5 minutes, get on the next one' that shouldn't be considered\n",
    "\n",
    "weekday_edges_pre_walking = {} #*\n",
    "\n",
    "print('Removing erroneous transfers...')\n",
    "for start, ends in edges_with_all_transfers.items():\n",
    "    for end, time_tup in ends.items():\n",
    "        if end != start:\n",
    "            if start not in weekday_edges_pre_walking:\n",
    "                weekday_edges_pre_walking[start] = {} #*\n",
    "            weekday_edges_pre_walking[start][end] = time_tup #*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing:  H01N#AR Aqueduct Racetrack\n"
     ]
    }
   ],
   "source": [
    "# create a dict of all neighbors of a given station-- including after a transfer. #*** whole cell\n",
    "# This will be used to filter walk stations\n",
    "\n",
    "within_one_stop = {}\n",
    "\n",
    "def get_transfers(stop):\n",
    "    transfers = []\n",
    "    for edge, time_tup in stop.items():\n",
    "        if time_tup[0] == 't':\n",
    "            transfers.append(edge)\n",
    "    return transfers\n",
    "\n",
    "# within_one_stop should include:\n",
    "# next stop and its transfers\n",
    "# transfers and their next stops and their transfers\n",
    "\n",
    "\n",
    "for stop, next_stop in next_stop_by_stop.items():\n",
    "    if next_stop[0] not in weekday_edges_pre_walking:\n",
    "        print('missing: ', next_stop[0], get_name(next_stop[0]))\n",
    "    else:\n",
    "        next_transfers = get_transfers(weekday_edges_pre_walking[next_stop[0]]) #transfers of next stop\n",
    "        transfers = get_transfers(weekday_edges_pre_walking[stop]) #transfers of current stop\n",
    "        if transfers:\n",
    "            transfer_next_neighbors = []\n",
    "            transfer_nexts = [] # next stop of each transfer\n",
    "            for t in transfers:\n",
    "                try:\n",
    "                    n = next_stop_by_stop[t]\n",
    "                    transfer_nexts += n\n",
    "                    transfer_next_neighbors += get_transfers(weekday_edges_pre_walking[n[0]])\n",
    "                except KeyError:\n",
    "                    pass # ignore keyerror that arises when looking for next stop of final stops\n",
    "        full = next_stop + next_transfers + transfers + transfer_nexts + transfer_next_neighbors\n",
    "        within_one_stop[stop] = list(set(full))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within_one_stop is missing final stops and 1 random AR stop... code it in for now, find better solution #***\n",
    "\n",
    "within_one_stop['H02N#AR'] = ['H01N#AR', 'H03N#AR', 'H03S#AR', 'A61N#AR', 'A61S#AR', 'A61S#AL', 'A61N#AL']\n",
    "\n",
    "missing = ['101N#1', '142S#1', '247S#2', '247S#5', '201N#2', '257S#3', '250S#4', '301N#3', '640S#6', '401N#4', '501N#5', '601N#6', '726S#7', '701N#7', '901S#GS', '902N#GS', 'A02N#AR', 'A02N#AL', 'A09N#C', 'A55S#C', 'H04N#H', 'H11S#AR', 'D13N#B', 'D26S#FS', 'D40S#B', 'D43S#D', 'D43S#F', 'D43S#N', 'D43S#Q', 'D01N#D', 'E01S#E', 'G08N#M', 'G08N#R', 'G05N#E', 'G05N#J', 'F27S#G', 'F01N#F', 'S01N#FS', 'G22N#G', 'H15S#H', 'M23S#J', 'L01N#L', 'L29S#L', 'M01S#M', 'R01N#N', 'R01N#W', 'R27S#W', 'Q05N#Q', 'R45S#R']\n",
    "\n",
    "for stop in missing:\n",
    "    within_one_stop[stop] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4851 walking edges added.\n"
     ]
    }
   ],
   "source": [
    "# add walking transfers #*** this whole cell\n",
    "\n",
    "# 1. find distance nevins to hoyt-- 1/3 of a mile-- this is the max walk distance. Say it's 6 minutes\n",
    "\n",
    "nevins = [40.688246, -73.980492]\n",
    "hoyt = [40.690545, -73.985065]\n",
    "\n",
    "a_sq = (nevins[0] - hoyt[0]) ** 2\n",
    "b_sq = (nevins[1] - hoyt[1]) ** 2\n",
    "\n",
    "max_walk = math.sqrt(a_sq + b_sq)\n",
    "max_walk_time = 360\n",
    "walk_per_second = max_walk_time / max_walk\n",
    "\n",
    "# 2. measure distance of every station to every other station!?\n",
    "\n",
    "weekday_edges_with_walking = dict(weekday_edges_pre_walking)\n",
    "\n",
    "count = 0\n",
    "\n",
    "missing_from_within = []\n",
    "\n",
    "for start, ends in weekday_edges_pre_walking.items():\n",
    "    for end in weekday_edges_pre_walking:\n",
    "        if end != start and end not in within_one_stop[start]:\n",
    "            start_lat, start_long = stations[start[:4]]['lat'], stations[start[:4]]['lon']\n",
    "            end_lat, end_long = stations[end[:4]]['lat'], stations[end[:4]]['lon']\n",
    "            a_sq = (start_lat - end_lat) ** 2\n",
    "            b_sq = (start_long - end_long) ** 2\n",
    "            distance = math.sqrt(a_sq + b_sq)\n",
    "            # 3. Do the math to translate into time, add to edges as ('w', time)\n",
    "            if distance <= max_walk:\n",
    "                #print(get_name(start),' ', start, '\\t to: ', get_name(end), ' ', end)\n",
    "                count += 1\n",
    "                time = math.ceil(walk_per_second * distance) + WAIT_TIME\n",
    "                weekday_edges_with_walking[start][end] = ('w', time)\n",
    "                \n",
    "\n",
    "print(count, 'walking edges added.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in two missing stations (?) #TODO debug why this is happening? #***\n",
    "\n",
    "weekday_edges = dict(weekday_edges_with_walking)\n",
    "\n",
    "weekday_edges['A65S#AL'] = {'A65N#AL': ('t', WAIT_TIME)}\n",
    "weekday_edges['H01N#AR'] = {'A61N#AR': ('r', 180)}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding children for all nodes...\n"
     ]
    }
   ],
   "source": [
    "# build node_children: for each node, all neighboring nodes (note that edges are directional)\n",
    "\n",
    "node_children = {}\n",
    "\n",
    "print('Finding children for all nodes...')\n",
    "for start, ends in weekday_edges.items():\n",
    "    parent = start[:3]\n",
    "    node_children[start] = []\n",
    "    node_children[start] += sub_stops[parent]\n",
    "    if start in node_children[start]:\n",
    "        node_children[start].remove(start)\n",
    "    for end, value in ends.items():\n",
    "        if end not in node_children[start] and end != start:\n",
    "            node_children[start].append(end)\n",
    "\n",
    "# remove self if in node_children\n",
    "for node, children in node_children.items():\n",
    "    if node in children:\n",
    "        node_children[node].remove(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating name to MTA ID station dictionary... in both directions...\n"
     ]
    }
   ],
   "source": [
    "name_to_stations = {} #*** this cell\n",
    "stations_with_full_name = dict(stations)\n",
    "\n",
    "\n",
    "print('Creating name to MTA ID station dictionary... in both directions...')\n",
    "for node, children in node_children.items():\n",
    "    comp = [get_line_name(child) for child in children if get_name(child) == get_name(node) and weekday_edges[node][child][0]=='t'] #*\n",
    "    children_lines = sorted(list(set(comp)))\n",
    "    name = get_name(node) + ' ' + '-'.join(children_lines)\n",
    "    if name not in name_to_stations:\n",
    "        children = [child for child in children if get_name(child) == get_name(node) and weekday_edges[node][child][0]=='t'] + [node]\n",
    "        name_to_stations[name] = children\n",
    "    stations_with_full_name[node[:3]]['full_name'] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing all data to disk.\n"
     ]
    }
   ],
   "source": [
    "print('Writing all data to disk.')\n",
    "with open('./graph/station_names.json', 'w') as name_file:\n",
    "    json.dump(name_to_stations, name_file, indent=2)\n",
    "\n",
    "with open('./graph/all_names.json', 'w') as all_name_file:\n",
    "    json.dump(list(name_to_stations.keys()), all_name_file, indent=2)\n",
    "\n",
    "with open('./graph/graph_network.json', 'w') as graph_file:\n",
    "    json.dump(node_children, graph_file, indent=2)\n",
    "\n",
    "with open('./graph/costs.json', 'w') as cost_file:\n",
    "    json.dump(weekday_edges, cost_file, indent=2)\n",
    "\n",
    "with open('./graph/stations.json', 'w') as stations_file:\n",
    "    json.dump(stations_with_full_name, stations_file, indent=2)\n",
    "\n",
    "# exported all of these which are then imported by the REST server to run the algo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
